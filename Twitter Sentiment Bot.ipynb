{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import tweepy\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter API Keys\n",
    "from config import (consumer_key, \n",
    "                    consumer_secret, \n",
    "                    access_token, \n",
    "                    access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up authentication to Twitter\n",
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser(), wait_on_rate_limit = \n",
    "                 True, wait_on_rate_limit_notify = True)\n",
    "\n",
    "my_twitter = \"@TheBadChai\"\n",
    "\n",
    "home_twitter_name = \"@TheBadChai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Works\n"
     ]
    }
   ],
   "source": [
    "#create function for analyzing tweets:\n",
    "def analyze_query_tweet():\n",
    "# Variables for holding sentiments\n",
    "    counter = 1\n",
    "    compound = []\n",
    "\n",
    "# Loop through 5 pages of tweets (total 100 tweets)\n",
    "    for x in range(25):\n",
    "\n",
    "    # Get all tweets from home feed\n",
    "        public_tweets = api.user_timeline(analysis_target, page=x)\n",
    "\n",
    "    # Loop through all tweets\n",
    "        for tweet in public_tweets:\n",
    "\n",
    "        # Print Tweets\n",
    "        # print(\"Tweet %s: %s\" % (counter, tweet[\"text\"]))\n",
    "\n",
    "        # Run Vader Analysis on each tweet\n",
    "            compound.append(analyzer.polarity_scores(tweet[\"text\"])[\"compound\"])\n",
    "            tweets_ago = counter\n",
    "\n",
    "        sentiments_pd = pd.DataFrame({\"Compound\" : compound})\n",
    "\n",
    "\n",
    "    plt.plot(np.arange(len(sentiments_pd[\"Compound\"])),\n",
    "         sentiments_pd[\"Compound\"], marker=\"o\", linewidth=0.5,\n",
    "         alpha=0.8)\n",
    "\n",
    "# # Incorporate the other graph properties\n",
    "    plt.title(\"Sentiment Analysis of Tweets (%s) for %s\" % (time.strftime(\"%x\"), analysis_target))\n",
    "    plt.legend(title= \"Tweets\", bbox_to_anchor=(1,1), loc='upper left', labels='@%s' % analysis_target)\n",
    "    plt.ylabel(\"Tweet Polarity\")\n",
    "    plt.xlabel(\"Tweets Ago\")\n",
    "    plt.grid(True)\n",
    "    Chart_file_name = \"sentimentAnalysis_\" + analysis_target + '.png'\n",
    "    plt.savefig(Chart_file_name, bbox_inches=\"tight\")\n",
    "    api.update_with_media(Chart_file_name, \"Analysis for a new tweet: @\" + analysis_target + \". Thanks @\" + query_user)\n",
    "print(\"Function Works\")\n",
    "\n",
    "while(True):\n",
    "\n",
    "    already_analyzed_users = []\n",
    "    pub_tweets = api.user_timeline(home_twitter_name, count=100)\n",
    "    for tweet in pub_tweets:\n",
    "        try:\n",
    "            already_analyzed_users.append(tweet['entities']['user_mentions'][0]['screen_name'])\n",
    "        except:\n",
    "            continue\n",
    "    mentions = api.search(q=home_twitter_name, since_id=pub_tweets[0]['id'], result_type='recent')\n",
    "    for mention in mentions['statuses']:\n",
    "        if mention[\"entities\"][\"user_mentions\"][1][\"screen_name\"] not in already_analyzed_users:\n",
    "            analysis_target = mention[\"entities\"][\"user_mentions\"][1][\"screen_name\"]\n",
    "            query_user = mention[\"user\"][\"screen_name\"]\n",
    "            analyze_query_tweet()\n",
    "        else:\n",
    "            print(\"Already analyzed user.\")\n",
    "\n",
    "    time.sleep(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
